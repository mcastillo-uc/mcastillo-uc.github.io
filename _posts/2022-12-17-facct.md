---
layout: post
title: FAccT - Fairness, Accountabily & Transparency
---

Vivimos actualmente Los grandes avances producidos en la inteligencia artificial, que nos ha permitido adquirir una capacidad jamás soñada de desarrollos, personalización, recomendación y sistemas automáticos de decsión. Los más curioso de esto es que sabemos que es una era donde esto está en su auge y parece que no se detendrá.

## Contexto

Vivimos actualmente Los grandes avances producidos en la inteligencia artificial, que nos ha permitido adquirir una capacidad jamás soñada de desarrollos, personalización, recomendación y sistemas automáticos de decsión. Los más curioso de esto es que sabemos que es una era donde esto está en su auge y parece que no se detendrá.

Naturalmente, un crecimiento tan desproporcional acarrea un sin fin de problemáticas a estudiar, que requieren tomar medidas. Así, como lo han hecho notar articulos de estudio e incluso documentales como :  

+ [Study finds gender and skin-type bias in commercial artificial-intelligence systems](https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212)
 + Software de analisis facial muestran un rango de error del 0.8% en personas de piel blanca, versus un 34,7% en personas de piel oscura.

![Joy Buolamwini](https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201802/MIT-Gender-Shades-01.jpg?itok=80zXry3B)

+ [Watch Coded Bias](https://www.netflix.com/cl/title/81328723)
  + Documental que analiza el descubrimiento hecho por Joy Buolamwini de MIT Media Lab sobre el sesgo racial presente en los algoritmos de tecnología y sus consecuencias.


## ¿Que es esto?

junto al increible numero de carácterisitcas que son capaces de tomar estos sistemas y su amplio abanico de implementación, estamos delegando a las máquinas cada vez más la experiencia y compromiso de DECISICIÓN del ser humano. Para poder reducir este impacto, la [Asociación de Mecanicas computacionales](https://facctconference.org/index.html) (ACM) creo una conferencia interdisciplinaria en la cual se dedica a distintas areas de investigación, computación, leyes, cientistas sociales y humanos para investigar los problemas que emergen de esta area.

## y en contreto trata de lo siguiente:

Tal como señala el titulo de este Blog trata de lidiar con los siguientes tópicos:

### Fairness (Justicia)

Aspiramos a modelos no sesgados. Si bien es deseable, es claro que muchos contextos reales son sesgados. Si bien será una tarea dificil, creo que aquí la busqueda escencial es que la descisión del sistema sea justa y no utilice elementos fuera del contexto del problema, por ejemplo: caracteristica de color de piel, para juzgar decisiones financieras. o usar el genero para determinar proyecciones futuras.

### Accountability (Explicabilidad, Rendir cuentas)

Sujeto en un marco donde el usuario tiene derecho a saber que elementos son los utilizados para tomar decisiones respecto a su perfil de cliente. y como como tal, existen articulos de leí que hacen esto una demanda a responder (GDPR). Este punto habla de la capacidad del ser humano para poder interpretar lo que realiza su algoritmo, este punto es interesante porque tambien dependerá del nivel de satisfacción y conocimiento del usuario respecto a la información entregada.

Como mencionan Friedman an Nissembaum (1994) un sistema computacional es segado si de manera sistematica discrimina a cierto grupo de personas a favor de otras.

### Transparency (Transparencia)

En una idea muy general es explicar como el sistema trabaja.

Es importante distinguir que la Accountability es distinta de la transparencia, yo puedo explicar como funciona el modelo, sin tener la necesidad de descubrir completamente la caja negra encargada de por ejemplo hacer la decisión.

En el ambito de la transparencia es increible como la visualización funciona de manera contundente de apoyo para mostrar el porqué y como se generan las decisiones/recomendaciones de los sistemas, entregando transparencia. aquí encuentro fascinante principalmente dos ejemplos:

1. Each to his own: una pequeña visualización para la justificación de reglas asociadas a decisiones en implementaciones domiciliarias. La cual llegó a la conclusión de que las reglas que satisfacían al usuario estaban ligadas al conocimiento de este en el tópico de uso.

"es importante saber que nuestra respuesta debe ser acorde al conocimiento del usuario en el tema".

2. Explain or not: recomendador de música, donde los desarrolladores llegaron a la conclusión de que el control y conocimiento de la selección podrían ser incluso más importante que la recomendación.

"la sensación de control y transparencia en los sistemas a favor del usuario se presentan como características deseadas!

