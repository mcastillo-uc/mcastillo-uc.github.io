---
layout: post
title: FAccT
---

# FAccT - Fairness, Accountabily & Transparency

## Contexto

Vivimos actualmente Los grandes avances producidos en la inteligencia artificial, que nos ha permitido adquirir una capacidad jamás soñada de desarrollos, personalización, recomendación y sistemas automáticos de decsión. Los más curioso de esto es que sabemos que es una era donde esto está en su auge y parece que no se detendrá.

Naturalmente, un crecimiento tan desproporcional acarrea un sin fin de problemáticas a estudiar, que requieren tomar medidas. Así, como lo han hecho notar articulos de estudio e incluso documentales como :  

+ [Study finds gender and skin-type bias in commercial artificial-intelligence systems](https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212)
 + Software de analisis facial muestran un rango de error del 0.8% en personas de piel blanca, versus un 34,7% en personas de piel oscura.

![Joy Buolamwini](https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201802/MIT-Gender-Shades-01.jpg?itok=80zXry3B)

+ [Watch Coded Bias](https://www.netflix.com/cl/title/81328723)
  + Documental que analiza el descubrimiento hecho por Joy Buolamwini de MIT Media Lab sobre el sesgo racial presente en los algoritmos de tecnología y sus consecuencias.


## ¿Que es esto?

junto al increible numero de carácterisitcas que son capaces de tomar estos sistemas y su amplio abanico de implementación, estamos delegando a las máquinas cada vez más la experiencia y compromiso de DECISICIÓN del ser humano. Para poder reducir este impacto, la [Asociación de Mecanicas computacionales](https://facctconference.org/index.html) (ACM) creo una conferencia interdisciplinaria en la cual se dedica a distintas areas de investigación, computación, leyes, cientistas sociales y humanos para investigar los problemas que emergen de esta area.

## y en contreto trata de lo siguiente:

Tal como señala el titulo de este Blog trata de lidiar con los siguientes tópicos:

### Fairness (Justicia)

Aspiramos a modelos no sesgados. Si bien es deseable, es claro que muchos contextos reales son sesgados. Si bien será una tarea dificil, creo que aquí la busqueda escencial es que la descisión del sistema sea justa y no utilice elementos fuera del contexto del problema, por ejemplo: caracteristica de color de piel, para juzgar decisiones financieras. o usar el genero para determinar proyecciones futuras.

### Accountability (Explicabilidad, Rendir cuentas)

Sujeto en un marco donde el usuario tiene derecho a saber que elementos son los utilizados para tomar decisiones respecto a su perfil de cliente. y como como tal, existen articulos de leí que hacen esto una demanda a responder (GDPR). Este punto habla de la capacidad del ser humano para poder interpretar lo que realiza su algoritmo, este punto es interesante porque tambien dependerá del nivel de satisfacción y conocimiento del usuario respecto a la información entregada.

### Transparency



![_config.yml]({{ site.baseurl }}/images/config.png)
